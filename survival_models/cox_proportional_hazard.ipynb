{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af45f419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lifelines\n",
      "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from lifelines) (2.3.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from lifelines) (1.16.0)\n",
      "Requirement already satisfied: pandas>=2.1 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from lifelines) (2.3.1)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from lifelines) (3.10.3)\n",
      "Collecting autograd>=1.5 (from lifelines)\n",
      "  Downloading autograd-1.8.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting autograd-gamma>=0.3 (from lifelines)\n",
      "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting formulaic>=0.2.2 (from lifelines)\n",
      "  Downloading formulaic-1.2.1-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n",
      "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting narwhals>=1.17 (from formulaic>=0.2.2->lifelines)\n",
      "  Downloading narwhals-2.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from formulaic>=0.2.2->lifelines) (4.15.0)\n",
      "Collecting wrapt>=1.17.0rc1 (from formulaic>=0.2.2->lifelines)\n",
      "  Downloading wrapt-2.0.0rc3-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from matplotlib>=3.0->lifelines) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from matplotlib>=3.0->lifelines) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from matplotlib>=3.0->lifelines) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from matplotlib>=3.0->lifelines) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from matplotlib>=3.0->lifelines) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from matplotlib>=3.0->lifelines) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from pandas>=2.1->lifelines) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from pandas>=2.1->lifelines) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gymmnotjim/Documents/[01]_PARA/[01]_Projects/university/intro_to_ai/homework/.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n",
      "Downloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
      "Downloading autograd-1.8.0-py3-none-any.whl (51 kB)\n",
      "Downloading formulaic-1.2.1-py3-none-any.whl (117 kB)\n",
      "Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
      "Downloading narwhals-2.6.0-py3-none-any.whl (408 kB)\n",
      "Downloading wrapt-2.0.0rc3-cp313-cp313-macosx_11_0_arm64.whl (59 kB)\n",
      "Building wheels for collected packages: autograd-gamma\n",
      "  Building wheel for autograd-gamma (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4119 sha256=4fe5eacb311f62d60a7eb70ecc63704a36acd802c38d9350289f06609c24b442\n",
      "  Stored in directory: /Users/gymmnotjim/Library/Caches/pip/wheels/7e/16/46/9477f188924292d3bf1fb8fb42844201591abfc19b7ba6d868\n",
      "Successfully built autograd-gamma\n",
      "Installing collected packages: wrapt, narwhals, interface-meta, autograd, autograd-gamma, formulaic, lifelines\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [lifelines]/7\u001b[0m [lifelines]meta]\n",
      "\u001b[1A\u001b[2KSuccessfully installed autograd-1.8.0 autograd-gamma-0.5.0 formulaic-1.2.1 interface-meta-1.3.0 lifelines-0.30.0 narwhals-2.6.0 wrapt-2.0.0rc3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526a8634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   week  arrest  fin  age  race  wexp  mar  paro  prio\n",
      "0    20       1    0   27     1     0    0     1     3\n",
      "1    17       1    0   18     1     0    0     1     8\n",
      "2    25       1    0   19     0     1    0     1    13\n",
      "3    52       0    1   23     1     1    1     1     1\n",
      "4    52       0    0   19     0     1    0     1     3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>lifelines.CoxPHFitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration col</th>\n",
       "      <td>'week'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event col</th>\n",
       "      <td>'arrest'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline estimation</th>\n",
       "      <td>breslow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of observations</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of events observed</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial log-likelihood</th>\n",
       "      <td>-658.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time fit was run</th>\n",
       "      <td>2025-10-04 14:45:06 UTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th style=\"min-width: 12px;\"></th>\n",
       "      <th style=\"min-width: 12px;\">coef</th>\n",
       "      <th style=\"min-width: 12px;\">exp(coef)</th>\n",
       "      <th style=\"min-width: 12px;\">se(coef)</th>\n",
       "      <th style=\"min-width: 12px;\">coef lower 95%</th>\n",
       "      <th style=\"min-width: 12px;\">coef upper 95%</th>\n",
       "      <th style=\"min-width: 12px;\">exp(coef) lower 95%</th>\n",
       "      <th style=\"min-width: 12px;\">exp(coef) upper 95%</th>\n",
       "      <th style=\"min-width: 12px;\">cmp to</th>\n",
       "      <th style=\"min-width: 12px;\">z</th>\n",
       "      <th style=\"min-width: 12px;\">p</th>\n",
       "      <th style=\"min-width: 12px;\">-log2(p)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fin</th>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.98</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.61</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>0.31</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wexp</th>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mar</th>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paro</th>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prio</th>\n",
       "      <td>0.09</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.19</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>9.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><br><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Concordance</th>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partial AIC</th>\n",
       "      <td>1331.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log-likelihood ratio test</th>\n",
       "      <td>33.27 on 7 df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-log2(p) of ll-ratio test</th>\n",
       "      <td>15.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "\\begin{tabular}{lrrrrrrrrrrr}\n",
       " & coef & exp(coef) & se(coef) & coef lower 95% & coef upper 95% & exp(coef) lower 95% & exp(coef) upper 95% & cmp to & z & p & -log2(p) \\\\\n",
       "covariate &  &  &  &  &  &  &  &  &  &  &  \\\\\n",
       "fin & -0.38 & 0.68 & 0.19 & -0.75 & -0.00 & 0.47 & 1.00 & 0.00 & -1.98 & 0.05 & 4.40 \\\\\n",
       "age & -0.06 & 0.94 & 0.02 & -0.10 & -0.01 & 0.90 & 0.99 & 0.00 & -2.61 & 0.01 & 6.79 \\\\\n",
       "race & 0.31 & 1.37 & 0.31 & -0.29 & 0.92 & 0.75 & 2.50 & 0.00 & 1.02 & 0.31 & 1.70 \\\\\n",
       "wexp & -0.15 & 0.86 & 0.21 & -0.57 & 0.27 & 0.57 & 1.30 & 0.00 & -0.71 & 0.48 & 1.06 \\\\\n",
       "mar & -0.43 & 0.65 & 0.38 & -1.18 & 0.31 & 0.31 & 1.37 & 0.00 & -1.14 & 0.26 & 1.97 \\\\\n",
       "paro & -0.08 & 0.92 & 0.20 & -0.47 & 0.30 & 0.63 & 1.35 & 0.00 & -0.43 & 0.66 & 0.59 \\\\\n",
       "prio & 0.09 & 1.10 & 0.03 & 0.04 & 0.15 & 1.04 & 1.16 & 0.00 & 3.19 & 0.00 & 9.48 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "<lifelines.CoxPHFitter: fitted with 432 total observations, 318 right-censored observations>\n",
       "             duration col = 'week'\n",
       "                event col = 'arrest'\n",
       "      baseline estimation = breslow\n",
       "   number of observations = 432\n",
       "number of events observed = 114\n",
       "   partial log-likelihood = -658.75\n",
       "         time fit was run = 2025-10-04 14:45:06 UTC\n",
       "\n",
       "---\n",
       "           coef exp(coef)  se(coef)  coef lower 95%  coef upper 95% exp(coef) lower 95% exp(coef) upper 95%\n",
       "covariate                                                                                                  \n",
       "fin       -0.38      0.68      0.19           -0.75           -0.00                0.47                1.00\n",
       "age       -0.06      0.94      0.02           -0.10           -0.01                0.90                0.99\n",
       "race       0.31      1.37      0.31           -0.29            0.92                0.75                2.50\n",
       "wexp      -0.15      0.86      0.21           -0.57            0.27                0.57                1.30\n",
       "mar       -0.43      0.65      0.38           -1.18            0.31                0.31                1.37\n",
       "paro      -0.08      0.92      0.20           -0.47            0.30                0.63                1.35\n",
       "prio       0.09      1.10      0.03            0.04            0.15                1.04                1.16\n",
       "\n",
       "           cmp to     z      p  -log2(p)\n",
       "covariate                               \n",
       "fin          0.00 -1.98   0.05      4.40\n",
       "age          0.00 -2.61   0.01      6.79\n",
       "race         0.00  1.02   0.31      1.70\n",
       "wexp         0.00 -0.71   0.48      1.06\n",
       "mar          0.00 -1.14   0.26      1.97\n",
       "paro         0.00 -0.43   0.66      0.59\n",
       "prio         0.00  3.19 <0.005      9.48\n",
       "---\n",
       "Concordance = 0.64\n",
       "Partial AIC = 1331.50\n",
       "log-likelihood ratio test = 33.27 on 7 df\n",
       "-log2(p) of ll-ratio test = 15.37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example Usage\n",
    "import pandas as pd\n",
    "from lifelines.datasets import load_rossi\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "# Load the sample dataset\n",
    "df = load_rossi()\n",
    "print(df.head())\n",
    "\n",
    "# Create and fit the model\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df, duration_col='week', event_col='arrest')\n",
    "\n",
    "# Print the summary of the model\n",
    "cph.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae1de0",
   "metadata": {},
   "source": [
    "## Cox Example Explanation\n",
    "\n",
    "Targets\n",
    "- week = survival duration\n",
    "- arrest = whether the event (arrest) occurred (1) or was censored (0)\n",
    "we're predicting risk of arrest at X week given features\n",
    "\n",
    "Evaluations\n",
    "- Concordance (like ROC-AUC)\n",
    "- Partial log-likelihood (model fit-measure, lower = better)\n",
    "- Partial AIC (penalized fit score, lower = better)\n",
    "- Log-likelihood ratio test (overall model significance)\n",
    "\n",
    "Features Interpretation\n",
    "- coef: effect on the log hazard\n",
    "- exp(coef): hazard ratio\n",
    "- p: statistical significance (lower = more significance)\n",
    "\n",
    "How do I use these from Cox to get these exactly?\n",
    "\n",
    "Survival probability \n",
    "S(t∣X): the probability the patient survives beyond time \n",
    "\n",
    "Median survival time: the time at which \n",
    "S(t∣X)=0.5\n",
    "\n",
    "Expected survival time (with care, since it’s semi-parametric)\n",
    "\n",
    "- “What’s P(survive past t)?” → cph.predict_survival_function(X_new, times=[t])\n",
    "- “What’s the median survival?” → cph.predict_median(X_new)\n",
    "- “What’s the expected survival?” → compute RMST up to clinically meaningful tau via numeric integration of S(t|X). Use parametric AFT models if you require extrapolation beyond observed data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f81f878",
   "metadata": {},
   "source": [
    "Survival probability \n",
    "S(t∣X): the probability the patient survives beyond time \n",
    "\n",
    "\n",
    "Median survival time: the time at which \n",
    "S(t∣X)=0.5\n",
    "\n",
    "Expected survival time (with care, since it’s semi-parametric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701001e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _prepare_times(events_time, events_observed):\n",
    "    # returns sorted unique event times with indices where events occurred\n",
    "    order = np.argsort(events_time)\n",
    "    t_sorted = events_time[order]\n",
    "    e_sorted = events_observed[order]\n",
    "    return order, t_sorted, e_sorted\n",
    "\n",
    "def fit_cox_ph(X, durations, events, max_iter=100, tol=1e-6, ridge=1e-6, verbose=False):\n",
    "    \"\"\"\n",
    "    Fit CoxPH via Newton-Raphson with Breslow ties.\n",
    "    X: (n, p) numpy array (no intercept)\n",
    "    durations: (n,) times\n",
    "    events: (n,) binary (1=event, 0=censor)\n",
    "    Returns: dict with beta, var (covariance), baseline_survival (DataFrame)\n",
    "    \"\"\"\n",
    "    n, p = X.shape\n",
    "    # Ensure numpy arrays\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    durations = np.asarray(durations, dtype=float)\n",
    "    events = np.asarray(events, dtype=int)\n",
    "\n",
    "    # sort by time ascending so risk sets are suffix sums (we'll compute reverse cumulative sums)\n",
    "    order = np.argsort(durations)\n",
    "    durations_s = durations[order]\n",
    "    events_s = events[order]\n",
    "    X_s = X[order]\n",
    "\n",
    "    # initial beta\n",
    "    beta = np.zeros(p, dtype=float)\n",
    "\n",
    "    # unique event times and group indices for events\n",
    "    unique_times, inv_idx = np.unique(durations_s[events_s == 1], return_inverse=True)\n",
    "    # But for grouping we need mapping per event position; we'll compute group properties during iterations.\n",
    "\n",
    "    for itr in range(max_iter):\n",
    "        linpred = X_s.dot(beta)            # n\n",
    "        # numeric stability for exp\n",
    "        linpred_max = np.max(linpred)\n",
    "        exp_lin = np.exp(linpred - linpred_max)  # shift to avoid overflow\n",
    "        # compute cumulative sums over risk sets: since sorted ascending, risk set at time t_i is suffix starting at i\n",
    "        # suffix sums can be computed via reversed cumulative sum\n",
    "        exp_rev_cumsum = np.cumsum(exp_lin[::-1])[::-1]   # n\n",
    "        # weighted X sums over risk sets\n",
    "        X_weighted = X_s * exp_lin[:, None]\n",
    "        Xw_rev_cumsum = np.cumsum(X_weighted[::-1, :], axis=0)[::-1, :]  # n x p\n",
    "\n",
    "        # compute gradient and Hessian with Breslow for ties\n",
    "        # iterate unique times where events occur; for efficiency, find indices where events==1 and group by durations\n",
    "        event_idxs = np.where(events_s == 1)[0]\n",
    "        times_of_events = durations_s[event_idxs]\n",
    "        # group events by equal times\n",
    "        groups = {}\n",
    "        for idx, t in zip(event_idxs, times_of_events):\n",
    "            groups.setdefault(t, []).append(idx)\n",
    "\n",
    "        loglik = 0.0\n",
    "        grad = np.zeros(p, dtype=float)\n",
    "        hess = np.zeros((p, p), dtype=float)\n",
    "\n",
    "        for t, idxs in groups.items():\n",
    "            d = len(idxs)  # number of events at this time (ties)\n",
    "            # sum of X over events at this time\n",
    "            X_ev = X_s[idxs, :]           # d x p\n",
    "            sum_X_ev = np.sum(X_ev, axis=0)  # p\n",
    "\n",
    "            # risk set: those with time >= t: find first index where durations_s >= t\n",
    "            # because durations_s sorted ascending, find first index i s.t. durations_s[i] >= t\n",
    "            # using searchsorted\n",
    "            i = np.searchsorted(durations_s, t, side='left')\n",
    "            sum_risk = np.sum(exp_lin[i:])  # or exp_rev_cumsum[i]\n",
    "            sum_X_risk = np.sum(X_weighted[i:, :], axis=0)  # or Xw_rev_cumsum[i]\n",
    "\n",
    "            # Breslow approximation\n",
    "            loglik += np.sum(linpred[idxs]) - d * (np.log(sum_risk) + linpred_max)  # note shifting back\n",
    "            # gradient contribution\n",
    "            grad += np.sum(X_ev, axis=0) - d * (sum_X_risk / sum_risk)\n",
    "            # Hessian contribution:\n",
    "            # V = sum_j (exp_lp_j * X_j X_j^T) / sum_risk  - (sum_X_risk/sum_risk) (sum_X_risk/sum_risk)^T\n",
    "            sum_X2_risk = np.dot((X_s[i:].T * exp_lin[i:]), X_s[i:])  # p x p  (sum over j in risk of exp*X_j X_j^T)\n",
    "            V = sum_X2_risk / sum_risk - np.outer(sum_X_risk / sum_risk, sum_X_risk / sum_risk)\n",
    "            hess -= d * V\n",
    "\n",
    "        # add ridge for stability\n",
    "        hess_reg = hess - ridge * np.eye(p)  # note: Hessian is negative definite; we use -H in NR step\n",
    "        # Newton-Raphson step: solve H * delta = grad  (since we maximize loglik, we do beta_new = beta - H^{-1} grad; note our hess is negative)\n",
    "        try:\n",
    "            delta = np.linalg.solve(hess_reg, grad)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # fallback to pseudo-inverse\n",
    "            delta = np.linalg.pinv(hess_reg).dot(grad)\n",
    "\n",
    "        beta_new = beta - delta\n",
    "\n",
    "        step = np.linalg.norm(beta_new - beta)\n",
    "        beta = beta_new\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"iter {itr}: loglik={loglik:.6f}, ||delta||={step:.6g}\")\n",
    "\n",
    "        if step < tol:\n",
    "            break\n",
    "\n",
    "    # compute variance: negative inverse Hessian at solution\n",
    "    # recompute Hessian at final beta\n",
    "    linpred = X_s.dot(beta)\n",
    "    linpred_max = np.max(linpred)\n",
    "    exp_lin = np.exp(linpred - linpred_max)\n",
    "    X_weighted = X_s * exp_lin[:, None]\n",
    "    # recompute risk suffix sums\n",
    "    exp_rev_cumsum = np.cumsum(exp_lin[::-1])[::-1]\n",
    "    Xw_rev_cumsum = np.cumsum(X_weighted[::-1, :], axis=0)[::-1, :]\n",
    "\n",
    "    # recompute hessian properly\n",
    "    hess = np.zeros((p, p), dtype=float)\n",
    "    event_idxs = np.where(events_s == 1)[0]\n",
    "    times_of_events = durations_s[event_idxs]\n",
    "    groups = {}\n",
    "    for idx, t in zip(event_idxs, times_of_events):\n",
    "        groups.setdefault(t, []).append(idx)\n",
    "\n",
    "    for t, idxs in groups.items():\n",
    "        d = len(idxs)\n",
    "        i = np.searchsorted(durations_s, t, side='left')\n",
    "        sum_risk = np.sum(exp_lin[i:])\n",
    "        sum_X_risk = np.sum(X_weighted[i:, :], axis=0)\n",
    "        sum_X2_risk = np.dot((X_s[i:].T * exp_lin[i:]), X_s[i:])  # p x p\n",
    "        V = sum_X2_risk / sum_risk - np.outer(sum_X_risk / sum_risk, sum_X_risk / sum_risk)\n",
    "        hess -= d * V\n",
    "\n",
    "    # covariance = -inv(hess)\n",
    "    try:\n",
    "        cov = -np.linalg.inv(hess)\n",
    "    except np.linalg.LinAlgError:\n",
    "        cov = -np.linalg.pinv(hess)\n",
    "\n",
    "    # baseline hazard and baseline survival (Breslow)\n",
    "    # hazard increments at unique event times: delta_h(t) = d(t) / sum_{j in R(t)} exp(X_j beta)\n",
    "    uniq_times = np.array(sorted(groups.keys()))\n",
    "    baseline_hazard = []\n",
    "    baseline_surv = []\n",
    "    cum_h = 0.0\n",
    "    for t in uniq_times:\n",
    "        idxs = groups[t]\n",
    "        d = len(idxs)\n",
    "        i = np.searchsorted(durations_s, t, side='left')\n",
    "        sum_risk = np.sum(np.exp(X_s.dot(beta) - linpred_max)[i:]) * np.exp(linpred_max)  # unshift\n",
    "        # to avoid mixing shifted exponent, compute exp without shift for numerator/denom:\n",
    "        sum_risk_raw = np.sum(np.exp(X_s.dot(beta))[i:])\n",
    "        dh = d / sum_risk_raw\n",
    "        cum_h += dh\n",
    "        baseline_hazard.append((t, dh))\n",
    "        baseline_surv.append((t, np.exp(-cum_h)))\n",
    "\n",
    "    baseline_hazard_df = pd.DataFrame(baseline_hazard, columns=[\"time\", \"hazard\"])\n",
    "    baseline_surv_df = pd.DataFrame(baseline_surv, columns=[\"time\", \"S0\"])\n",
    "\n",
    "    # package results\n",
    "    # reorder beta back to original order\n",
    "    beta_full = beta.copy()\n",
    "    # create helper predict functions\n",
    "    def predict_partial_hazard(X_new):\n",
    "        return np.exp(np.dot(X_new, beta_full))\n",
    "\n",
    "    def predict_survival_function(X_new, times=None):\n",
    "        # times: array-like of times. returns DataFrame index=times, columns = rows of X_new\n",
    "        if times is None:\n",
    "            times = baseline_surv_df[\"time\"].values\n",
    "        times = np.asarray(times)\n",
    "        S0_t = np.interp(times, baseline_surv_df[\"time\"].values, baseline_surv_df[\"S0\"].values, left=1.0, right=baseline_surv_df[\"S0\"].values[-1])\n",
    "        ph = predict_partial_hazard(X_new)\n",
    "        # S(t|X) = S0(t)^{exp(Xb)}\n",
    "        out = np.vstack([S0_t ** ph_i for ph_i in ph])\n",
    "        # transpose -> index times, columns per sample\n",
    "        return pd.DataFrame(out.T, index=times, columns=np.arange(X_new.shape[0]))\n",
    "\n",
    "    return {\n",
    "        \"beta\": beta_full,\n",
    "        \"cov\": cov,\n",
    "        \"baseline_hazard\": baseline_hazard_df,\n",
    "        \"baseline_survival\": baseline_surv_df,\n",
    "        \"predict_survival_function\": predict_survival_function,\n",
    "        \"predict_partial_hazard\": predict_partial_hazard,\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# Quick usage example (synthetic)\n",
    "if __name__ == \"__main__\":\n",
    "    # small synthetic example\n",
    "    np.random.seed(0)\n",
    "    n = 200\n",
    "    p = 3\n",
    "    X = np.random.randn(n, p)\n",
    "    true_beta = np.array([0.5, -0.7, 0.0])\n",
    "    lin = X.dot(true_beta)\n",
    "    base_hazard = 0.01\n",
    "    # simulate exponential survival times with hazards h0 * exp(Xb)\n",
    "    U = np.random.rand(n)\n",
    "    times = -np.log(U) / (base_hazard * np.exp(lin))\n",
    "    # censor some at t=50\n",
    "    censoring = np.random.exponential(scale=100, size=n)\n",
    "    durations = np.minimum(times, censoring)\n",
    "    events = (times <= censoring).astype(int)\n",
    "\n",
    "    res = fit_cox_ph(X, durations, events, max_iter=50, tol=1e-6, verbose=True)\n",
    "    print(\"beta:\", res[\"beta\"])\n",
    "    print(\"cov diag:\", np.sqrt(np.diag(res[\"cov\"])))\n",
    "    # predict survival for first two rows\n",
    "    sf = res[\"predict_survival_function\"](X[:2, :], times=np.linspace(0, np.max(durations), 50))\n",
    "    print(sf.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Intro-to-ai",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
